{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a72517b-accc-42de-babd-70bb84d08a5c",
   "metadata": {},
   "source": [
    "# Group Convo Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b317d",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c80b0",
   "metadata": {},
   "source": [
    "Datasets used in the following experiments:\n",
    "\n",
    "1) GAP corpus\n",
    "2) UGI corpus\n",
    "\n",
    "The GAP corpus differs from the UGI corpus in that the GAP corpus has more metadata. Important metadata only in the GAP corpus includes utterance 'Duration' and 'End' metadata fields (describe temporal length of utterance). Features that depend on such metadata will therefore be exclusive to the GAP corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9274bed8",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9f638-41e2-4b8f-8b3c-002c69e12bbe",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e70f1c-d7f0-485b-95b2-cec1479687c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad36fe2-48ac-4a68-94a3-becc1fb6c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../../csv'\n",
    "\n",
    "gap_align_df = pd.read_csv(f'{csv_path}/gap-align.csv')\n",
    "gap_dom_df = pd.read_csv(f'{csv_path}/gap-dom.csv')\n",
    "gap_meta_df = pd.read_csv(f'{csv_path}/gap-meta.csv')\n",
    "gap_polite_df = pd.read_csv(f'{csv_path}/gap-polite.csv')\n",
    "gap_psych_df = pd.read_csv(f'{csv_path}/gap-psych.csv')\n",
    "\n",
    "ugi_align_df = pd.read_csv(f'{csv_path}/ugi-align.csv')\n",
    "ugi_dom_df = pd.read_csv(f'{csv_path}/ugi-dom.csv')\n",
    "ugi_meta_df = pd.read_csv(f'{csv_path}/ugi-meta.csv')\n",
    "ugi_polite_df = pd.read_csv(f'{csv_path}/ugi-polite.csv')\n",
    "ugi_psych_df = pd.read_csv(f'{csv_path}/ugi-psych.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85fe964-b297-44b1-b193-adac1d914ca6",
   "metadata": {},
   "source": [
    "### Combining Data Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a6d919-6d43-4c00-9e8f-77be0d7a077d",
   "metadata": {},
   "source": [
    "Each data group from the GAP corpus is combined with its UGI counterpart. Analysis is performed on combined data groups and individual data groups (since some features are exclusive to the GAP corpus). 10-fold cross-validation is used for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b4d1b10-509a-406b-a4ad-0b37e8e49f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the id column of meta_df does not necessarily hold unique values (depend on row num to remedy this)\n",
    "align_df = pd.concat([gap_align_df, ugi_align_df], ignore_index=True).dropna(axis=1)\n",
    "dom_df = pd.concat([gap_dom_df, ugi_dom_df], ignore_index=True).dropna(axis=1)\n",
    "meta_df = pd.concat([gap_meta_df, ugi_meta_df], ignore_index=True).dropna(axis=1)\n",
    "polite_df = pd.concat([gap_polite_df, ugi_polite_df], ignore_index=True).dropna(axis=1)\n",
    "psych_df = pd.concat([gap_psych_df, ugi_psych_df], ignore_index=True).dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4d8df",
   "metadata": {},
   "source": [
    "### Predicting AGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492bd172-fb00-44bf-8e48-bd44adedca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter lr = LinearRegression\n",
    "# Parameter rfr = RandomForestRegressor\n",
    "# Parameter gbr = GradientBoostingRegressor\n",
    "# Parameter mlpr = MLPRegressor\n",
    "def data_group_regression(x, y, lr, rfr, gbr, mlpr):\n",
    "    l_preds = regression_preds(X, y, lr)\n",
    "    evaluate_preds('Linear Regression', y, l_preds)\n",
    "    \n",
    "    rf_preds = regression_preds(X, y, rfr)\n",
    "    evaluate_preds('Random Forest', y, rf_preds)\n",
    "    \n",
    "    gb_preds = regression_preds(X, y, gbr)\n",
    "    evaluate_preds('Gradient Boosting', y, gb_preds)\n",
    "    \n",
    "    mlp_preds = scaled_regression_preds(X, y, mlpr)\n",
    "    evaluate_preds('Neural Network', y, mlp_preds)\n",
    "\n",
    "\n",
    "def regression_preds(x, y, regressor):\n",
    "    kf = KFold(n_splits=10)\n",
    "    preds = []\n",
    "    \n",
    "    for train, test in kf.split(X):\n",
    "        X_train = X.iloc[train]\n",
    "        y_train = y.iloc[train]\n",
    "        X_test = X.iloc[test]\n",
    "            \n",
    "        regressor.fit(X_train, y_train)\n",
    "        new_preds = regressor.predict(X_test)\n",
    "        preds.extend(list(new_preds))\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "def scaled_regression_preds(x, y, regressor):\n",
    "    kf = KFold(n_splits=10)\n",
    "    preds = []\n",
    "    \n",
    "    for train, test in kf.split(X):\n",
    "        X_train = X.iloc[train]\n",
    "        y_train = y.iloc[train]\n",
    "        X_test = X.iloc[test]\n",
    "\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "            \n",
    "        regressor.fit(X_train, y_train)\n",
    "        new_preds = regressor.predict(X_test)\n",
    "        preds.extend(list(new_preds))\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "def evaluate_preds(title, y, preds):\n",
    "    mse = mean_squared_error(y, preds)\n",
    "    r2 = r2_score(y, preds)\n",
    "    print(title)\n",
    "    print(\"\\tMSE:\", mse)\n",
    "    print(\"\\tR^2 score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb821896-845b-4c5d-a781-20acdb2b73cf",
   "metadata": {},
   "source": [
    "#### Exp 1 - Combined Align Data Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af3dab4f-8ea0-414b-8fef-defbb1f775db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "\tMSE: 488.07335617132907\n",
      "\tR^2 score: 0.044289437752003336\n",
      "Random Forest\n",
      "\tMSE: 415.9189364399946\n",
      "\tR^2 score: 0.18557709498257946\n",
      "Gradient Boosting\n",
      "\tMSE: 393.3041373864552\n",
      "\tR^2 score: 0.229859787420715\n",
      "Neural Network\n",
      "\tMSE: 2492.211383402689\n",
      "\tR^2 score: -3.880071227728612\n"
     ]
    }
   ],
   "source": [
    "df = align_df.join(meta_df)\n",
    "X = df.drop(['id', 'ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=6, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=4, max_features=1/3, random_state=0)\n",
    "\n",
    "# results are highly dependent on random state\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(4), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab21dc93-4344-45f1-82eb-d5ab2b250034",
   "metadata": {},
   "source": [
    "#### Exp 2 - Individual Align Data Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6074884a-59ae-46c1-9da0-fbf7f933ef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GAP DATASET\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 384.17913727114734\n",
      "\tR^2 score: -1.478187607439419\n",
      "Random Forest\n",
      "\tMSE: 154.4126566445844\n",
      "\tR^2 score: 0.003945048014594832\n",
      "Gradient Boosting\n",
      "\tMSE: 145.40477454944448\n",
      "\tR^2 score: 0.06205133128654616\n",
      "Neural Network\n",
      "\tMSE: 3839.7331738182693\n",
      "\tR^2 score: -23.76859944769599\n",
      "\n",
      "UGI DATASET\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 1086.7202667476429\n",
      "\tR^2 score: -11.223961353208585\n",
      "Random Forest\n",
      "\tMSE: 110.86205643891184\n",
      "\tR^2 score: -0.24703066181168798\n",
      "Gradient Boosting\n",
      "\tMSE: 138.45492465131963\n",
      "\tR^2 score: -0.5574087461940758\n",
      "Neural Network\n",
      "\tMSE: 689.852014397013\n",
      "\tR^2 score: -6.759793041000145\n"
     ]
    }
   ],
   "source": [
    "gap_df = gap_align_df.join(gap_meta_df)\n",
    "gap_X = gap_df.drop(['id', 'ags'], axis=1)\n",
    "gap_y = gap_df['ags']\n",
    "\n",
    "ugi_df = ugi_align_df.join(ugi_meta_df)\n",
    "ugi_X = ugi_df.drop(['id', 'ags'], axis=1)\n",
    "ugi_y = ugi_df['ags']\n",
    "\n",
    "dataset_params = {\n",
    "    'GAP': (gap_X, gap_y), \n",
    "    'UGI': (ugi_X, ugi_y)\n",
    "}\n",
    "\n",
    "for key, (X, y) in dataset_params.items():\n",
    "    print()\n",
    "    print(key, 'DATASET')\n",
    "    print()\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "    gbr = GradientBoostingRegressor(max_depth=4, max_features=1/3, random_state=0)\n",
    "    mlpr = MLPRegressor(hidden_layer_sizes=(4), max_iter=1000, activation='relu', random_state=0)\n",
    "    \n",
    "    data_group_regression(X, y, lr, rfr, gbr, mlpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d46e7-4c2e-4974-b689-316b23009969",
   "metadata": {},
   "source": [
    "#### Exp 3 - Combined Dom Data Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "425ea0d4-973a-49a7-82d3-b46828b643fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "\tMSE: 388.4520504363389\n",
      "\tR^2 score: 0.23936079928407106\n",
      "Random Forest\n",
      "\tMSE: 351.59264830679354\n",
      "\tR^2 score: 0.31153626120579714\n",
      "Gradient Boosting\n",
      "\tMSE: 354.12900153350654\n",
      "\tR^2 score: 0.3065697545573366\n",
      "Neural Network\n",
      "\tMSE: 3476.0098361477285\n",
      "\tR^2 score: -5.8064754465272745\n"
     ]
    }
   ],
   "source": [
    "df = dom_df.join(meta_df)\n",
    "X = df.drop(['id', 'ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=6, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=4, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(1), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f08c52-b1f2-4dbd-84cb-f9cbb9ba433c",
   "metadata": {},
   "source": [
    "#### Exp 4 - Individual Dom Data Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd62f557-3c0b-4b0f-81a9-44d39c9a589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GAP DATASET\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 197.11177258787373\n",
      "\tR^2 score: -0.2714900542944487\n",
      "Random Forest\n",
      "\tMSE: 183.5730041335352\n",
      "\tR^2 score: -0.18415681584258192\n",
      "Gradient Boosting\n",
      "\tMSE: 173.6349375998323\n",
      "\tR^2 score: -0.12005028080096536\n",
      "Neural Network\n",
      "\tMSE: 4577.586767729348\n",
      "\tR^2 score: -28.528201037525474\n",
      "\n",
      "UGI DATASET\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 133.35506192185505\n",
      "\tR^2 score: -0.5000429945658138\n",
      "Random Forest\n",
      "\tMSE: 104.22976954939237\n",
      "\tR^2 score: -0.17242745333052656\n",
      "Gradient Boosting\n",
      "\tMSE: 111.67308447424939\n",
      "\tR^2 score: -0.25615350203441234\n",
      "Neural Network\n",
      "\tMSE: 1138.5884770091905\n",
      "\tR^2 score: -11.807400364238356\n"
     ]
    }
   ],
   "source": [
    "gap_df = gap_dom_df.join(gap_meta_df)\n",
    "gap_X = gap_df.drop(['id', 'ags'], axis=1)\n",
    "gap_y = gap_df['ags']\n",
    "\n",
    "ugi_df = ugi_dom_df.join(ugi_meta_df)\n",
    "ugi_X = ugi_df.drop(['id', 'ags'], axis=1)\n",
    "ugi_y = ugi_df['ags']\n",
    "\n",
    "dataset_params = {\n",
    "    'GAP': {\n",
    "        'data': (gap_X, gap_y),\n",
    "        'mlpr': MLPRegressor(\n",
    "            hidden_layer_sizes=(2), max_iter=1000, activation='relu', random_state=0\n",
    "        )\n",
    "    },\n",
    "    'UGI': {\n",
    "        'data': (ugi_X, ugi_y),\n",
    "        'mlpr': MLPRegressor(\n",
    "            hidden_layer_sizes=(1), max_iter=1000, activation='relu', random_state=0\n",
    "        )\n",
    "    }\n",
    "}\n",
    "\n",
    "for key, params in dataset_params.items():\n",
    "    print()\n",
    "    print(key, 'DATASET')\n",
    "    print()\n",
    "\n",
    "    X, y = params['data']\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "    gbr = GradientBoostingRegressor(max_depth=4, max_features=1/3, random_state=0)\n",
    "    mlpr = params['mlpr']\n",
    "    \n",
    "    data_group_regression(X, y, lr, rfr, gbr, mlpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7c1d7-1a4e-422c-9215-cd5ecbcfa328",
   "metadata": {},
   "source": [
    "#### Exp 5 - Combined Polite Data Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eb0c817-699a-429d-93f3-c28ee957a6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "\tMSE: 324.83108385932957\n",
      "\tR^2 score: 0.36393885495800293\n",
      "Random Forest\n",
      "\tMSE: 431.44767804518574\n",
      "\tR^2 score: 0.15516981668547958\n",
      "Gradient Boosting\n",
      "\tMSE: 456.83569612211\n",
      "\tR^2 score: 0.1054568038281617\n",
      "Neural Network\n",
      "\tMSE: 1624.6313183369473\n",
      "\tR^2 score: -2.1812375968920326\n"
     ]
    }
   ],
   "source": [
    "df = polite_df.join(meta_df)\n",
    "X = df.drop(['id', 'ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=6, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=4, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(4), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0049217d-f295-4b1f-a1a3-bb1467ed8806",
   "metadata": {},
   "source": [
    "#### Exp 6 - Combined Psych Data Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa1cf32-0e54-49a9-8431-81781e0c77dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "\tMSE: 631.1033683199008\n",
      "\tR^2 score: -0.2357817679395957\n",
      "Random Forest\n",
      "\tMSE: 502.7865893696937\n",
      "\tR^2 score: 0.015479030064928345\n",
      "Gradient Boosting\n",
      "\tMSE: 611.5648091783905\n",
      "\tR^2 score: -0.19752274989130525\n",
      "Neural Network\n",
      "\tMSE: 1053.288896310023\n",
      "\tR^2 score: -1.0624754672096093\n"
     ]
    }
   ],
   "source": [
    "df = psych_df.join(meta_df)\n",
    "X = df.drop(['id', 'ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=6, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=4, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(7), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c963c2e0-790c-4fc0-b338-393d633884b9",
   "metadata": {},
   "source": [
    "## Summary of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5ef87-de4e-4519-b15c-6b713bbcde89",
   "metadata": {},
   "source": [
    "Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
