{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a72517b-accc-42de-babd-70bb84d08a5c",
   "metadata": {},
   "source": [
    "# Group Convo Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b317d",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c80b0",
   "metadata": {},
   "source": [
    "Datasets used in the following experiments:\n",
    "\n",
    "1) GAP corpus\n",
    "2) UGI corpus\n",
    "\n",
    "The GAP corpus differs from the UGI corpus in that the GAP corpus has more metadata. Important metadata only in the GAP corpus includes utterance 'Duration' and 'End' metadata fields (describe temporal length of utterance). Features that depend on such metadata will therefore be exclusive to the GAP corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9274bed8",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9f638-41e2-4b8f-8b3c-002c69e12bbe",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e70f1c-d7f0-485b-95b2-cec1479687c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# The MLP Regressor rarely converges, so this filters convergence failure warnings\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75596a0-697e-4e92-988f-efb63f5c5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../../csv'\n",
    "\n",
    "gap_align_df = pd.read_csv(f'{csv_path}/gap-align.csv')\n",
    "gap_dom_df = pd.read_csv(f'{csv_path}/gap-dom.csv')\n",
    "gap_meta_df = pd.read_csv(f'{csv_path}/gap-meta.csv')\n",
    "gap_polite_df = pd.read_csv(f'{csv_path}/gap-polite.csv')\n",
    "gap_psych_df = pd.read_csv(f'{csv_path}/gap-psych.csv')\n",
    "gap_rhythm_df = pd.read_csv(f'{csv_path}/gap-rhythm.csv')\n",
    "\n",
    "ugi_align_df = pd.read_csv(f'{csv_path}/ugi-align.csv')\n",
    "ugi_dom_df = pd.read_csv(f'{csv_path}/ugi-dom.csv')\n",
    "ugi_meta_df = pd.read_csv(f'{csv_path}/ugi-meta.csv')\n",
    "ugi_polite_df = pd.read_csv(f'{csv_path}/ugi-polite.csv')\n",
    "ugi_psych_df = pd.read_csv(f'{csv_path}/ugi-psych.csv')\n",
    "ugi_rhythm_df = pd.read_csv(f'{csv_path}/ugi-rhythm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d193c87-686c-488c-a2e6-59e82171b4b7",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d2df8eb-8649-4470-b5a3-de24d8d73afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There exists a disparity between the GAP and UGI average AGS (meta feature)\n",
    "# To combine the GAP and UGI datasets, the AGS feature must be scaled for both\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "gap_meta_df['ags'] = scaler.fit_transform(gap_meta_df[['ags']])\n",
    "ugi_meta_df['ags'] = scaler.fit_transform(ugi_meta_df[['ags']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85fe964-b297-44b1-b193-adac1d914ca6",
   "metadata": {},
   "source": [
    "### Combining Data Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a6d919-6d43-4c00-9e8f-77be0d7a077d",
   "metadata": {},
   "source": [
    "Each data group from the GAP corpus is combined with its UGI counterpart. Analysis is performed on combined data groups and individual data groups (since some features are exclusive to the GAP corpus). 10-fold cross-validation is used for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b4d1b10-509a-406b-a4ad-0b37e8e49f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the id column of meta_df does not necessarily hold unique values (depend on row num to remedy this)\n",
    "# Align feature values may be NaN, so can't use dropna to drop columns the ugi_align_df is missing\n",
    "\n",
    "align_df = pd.concat([gap_align_df, ugi_align_df], ignore_index=True).drop(['src-10'], axis=1)\n",
    "dom_df = pd.concat([gap_dom_df, ugi_dom_df], ignore_index=True).dropna(axis=1)\n",
    "meta_df = pd.concat([gap_meta_df, ugi_meta_df], ignore_index=True).dropna(axis=1)\n",
    "polite_df = pd.concat([gap_polite_df, ugi_polite_df], ignore_index=True).dropna(axis=1)\n",
    "psych_df = pd.concat([gap_psych_df, ugi_psych_df], ignore_index=True).dropna(axis=1)\n",
    "rhythm_df = pd.concat([gap_rhythm_df, ugi_rhythm_df], ignore_index=True).dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4d8df",
   "metadata": {},
   "source": [
    "### Predicting AGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "492bd172-fb00-44bf-8e48-bd44adedca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter lr = LinearRegression\n",
    "# Parameter rfr = RandomForestRegressor\n",
    "# Parameter gbr = GradientBoostingRegressor\n",
    "# Parameter mlpr = MLPRegressor\n",
    "def data_group_regression(x, y, lr, rfr, gbr, mlpr, feat_percentage=None):\n",
    "    l_preds = regression_preds(x, y, lr, feat_percentage)\n",
    "    evaluate_preds('Linear Regression', y, l_preds)\n",
    "    \n",
    "    rf_preds = regression_preds(x, y, rfr, feat_percentage)\n",
    "    evaluate_preds('Random Forest', y, rf_preds)\n",
    "    \n",
    "    gb_preds = regression_preds(x, y, gbr, feat_percentage)\n",
    "    evaluate_preds('Gradient Boosting', y, gb_preds)\n",
    "    \n",
    "    mlp_preds = regression_preds(x, y, mlpr, feat_percentage, True)\n",
    "    evaluate_preds('Neural Network', y, mlp_preds)\n",
    "\n",
    "\n",
    "# To use less than 100% of features, set parameter feat_percentage\n",
    "def regression_preds(x, y, regressor, feat_percentage=None, scaled=False):\n",
    "    kf = KFold(n_splits=10)\n",
    "    preds = []\n",
    "    \n",
    "    for train, test in kf.split(x):\n",
    "        x_train = x.iloc[train]\n",
    "        y_train = y.iloc[train]\n",
    "        x_test = x.iloc[test]\n",
    "\n",
    "        if scaled:\n",
    "            scaler = StandardScaler().set_output(transform=\"pandas\").fit(x_train)\n",
    "            x_train = scaler.transform(x_train)\n",
    "            x_test = scaler.transform(x_test)\n",
    "\n",
    "        if feat_percentage:\n",
    "            x_train, x_test = select_features(\n",
    "                x_train, y_train, x_test, feat_percentage\n",
    "            )\n",
    "            \n",
    "        regressor.fit(x_train, y_train)\n",
    "        new_preds = regressor.predict(x_test)\n",
    "        preds.extend(list(new_preds))\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "def select_features(x_train, y_train, x_test, feat_percentage):\n",
    "\n",
    "    if not (0 < feat_percentage < 100):\n",
    "        raise Exception(\n",
    "            'Parameter feat_percentage must be a value in range (0, 100)'\n",
    "        )\n",
    "\n",
    "    selector = SelectPercentile(f_regression, percentile=feat_percentage)\n",
    "    selector.fit_transform(x_train, y_train)\n",
    "    selected_cols = selector.get_support()    \n",
    "    selected_feats = x_train.columns.values[selected_cols]\n",
    "\n",
    "    x_train_sub = x_train[selected_feats]\n",
    "    x_test_sub = x_test[selected_feats]\n",
    "\n",
    "    return x_train_sub, x_test_sub\n",
    "        \n",
    "\n",
    "def evaluate_preds(title, y, preds):\n",
    "    mse = mean_squared_error(y, preds)\n",
    "    r2 = r2_score(y, preds)\n",
    "    print(title)\n",
    "    print(\"\\tMSE:\", mse)\n",
    "    print(\"\\tR^2 score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501319c-621e-4a89-9021-f32d91ec07cc",
   "metadata": {},
   "source": [
    "#### Exp 1 - Combined Meta Data Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284a35db-ed9d-463a-ab37-7c0df36bf170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.07395253467500197\n",
      "\tR^2 score: -0.03468072377639286\n",
      "Random Forest\n",
      "\tMSE: 0.0696869513448505\n",
      "\tR^2 score: 0.024999676182386743\n",
      "Gradient Boosting\n",
      "\tMSE: 0.07852747128914231\n",
      "\tR^2 score: -0.09868933075589026\n",
      "Neural Network\n",
      "\tMSE: 0.09968333986643133\n",
      "\tR^2 score: -0.3946841808021446\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.07050949657032586\n",
      "\tR^2 score: 0.013491325684680922\n",
      "Random Forest\n",
      "\tMSE: 0.06615564653797393\n",
      "\tR^2 score: 0.0744066779776773\n",
      "Gradient Boosting\n",
      "\tMSE: 0.0955269761777764\n",
      "\tR^2 score: -0.3365318888143882\n",
      "Neural Network\n",
      "\tMSE: 0.08620357127386168\n",
      "\tR^2 score: -0.2060867678129612\n"
     ]
    }
   ],
   "source": [
    "# 2 features\n",
    "\n",
    "X = meta_df.drop(['id', 'ags'], axis=1)\n",
    "y = meta_df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(1), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "print('Feature percentage = 100%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "# Feature total_mins is the most useful\n",
    "feat_perc = 50\n",
    "print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb821896-845b-4c5d-a781-20acdb2b73cf",
   "metadata": {},
   "source": [
    "#### Exp 2 - Combined Align Data Group (Excluding NaN Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8484d2c-10ba-4f10-a3b4-01d1466ea043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.09104352234755239\n",
      "\tR^2 score: -0.27380323083855407\n",
      "Random Forest\n",
      "\tMSE: 0.08953790056539868\n",
      "\tR^2 score: -0.2527378563772389\n",
      "Gradient Boosting\n",
      "\tMSE: 0.13504371030572676\n",
      "\tR^2 score: -0.8894162929591996\n",
      "Neural Network\n",
      "\tMSE: 0.09234090513943966\n",
      "\tR^2 score: -0.2919551031445442\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.08316517257464988\n",
      "\tR^2 score: -0.16357608742806828\n",
      "Random Forest\n",
      "\tMSE: 0.09407344356005863\n",
      "\tR^2 score: -0.31619530146762354\n",
      "Gradient Boosting\n",
      "\tMSE: 0.1361011973681058\n",
      "\tR^2 score: -0.9042117490432273\n",
      "Neural Network\n",
      "\tMSE: 0.0783306829686039\n",
      "\tR^2 score: -0.0959360365947064\n"
     ]
    }
   ],
   "source": [
    "# 3 features\n",
    "\n",
    "df = align_df.join(meta_df['ags']).dropna(axis=1)\n",
    "X = df.drop(['ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(1), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "print('Feature percentage = 100%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "feat_perc = 50\n",
    "print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e9c58-cdc5-4460-b183-d10d698353e9",
   "metadata": {},
   "source": [
    "#### Exp 3 - Combined Align Data Group (Excluding NaN Rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f78fe255-5288-4f03-a7e3-99f4fc32c857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.10253769540559236\n",
      "\tR^2 score: -0.3423241701824218\n",
      "Random Forest\n",
      "\tMSE: 0.07947434314952079\n",
      "\tR^2 score: -0.04040110611999603\n",
      "Gradient Boosting\n",
      "\tMSE: 0.115748448397532\n",
      "\tR^2 score: -0.5152665498335949\n",
      "Neural Network\n",
      "\tMSE: 0.2055160135007113\n",
      "\tR^2 score: -1.690416545742805\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.08149091369612699\n",
      "\tR^2 score: -0.06680009407150256\n",
      "Random Forest\n",
      "\tMSE: 0.08030585373786231\n",
      "\tR^2 score: -0.05128643717876846\n",
      "Gradient Boosting\n",
      "\tMSE: 0.11985472295825858\n",
      "\tR^2 score: -0.5690219182419225\n",
      "Neural Network\n",
      "\tMSE: 0.25858503519227377\n",
      "\tR^2 score: -2.385144764694314\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "\n",
    "df = align_df.join(meta_df['ags']).dropna()\n",
    "X = df.drop(['ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(4), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "print('Feature percentage = 100%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "feat_perc = 50\n",
    "print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab21dc93-4344-45f1-82eb-d5ab2b250034",
   "metadata": {},
   "source": [
    "#### Exp 4 - Individual Align Data Groups (Excluding NaN Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6074884a-59ae-46c1-9da0-fbf7f933ef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GAP DATASET\n",
      "\n",
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.09482456744768539\n",
      "\tR^2 score: -0.7181972256565372\n",
      "Random Forest\n",
      "\tMSE: 0.04976166194124794\n",
      "\tR^2 score: 0.0983312469241564\n",
      "Gradient Boosting\n",
      "\tMSE: 0.0463023639316272\n",
      "\tR^2 score: 0.16101285363044282\n",
      "Neural Network\n",
      "\tMSE: 0.07628725193575217\n",
      "\tR^2 score: -0.3823057479411702\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.0709166381256623\n",
      "\tR^2 score: -0.28499158140241887\n",
      "Random Forest\n",
      "\tMSE: 0.06039630224536123\n",
      "\tR^2 score: -0.0943657508919793\n",
      "Gradient Boosting\n",
      "\tMSE: 0.06989555844647913\n",
      "\tR^2 score: -0.2664898753660092\n",
      "Neural Network\n",
      "\tMSE: 0.1443133390305805\n",
      "\tR^2 score: -1.6149212743245394\n",
      "\n",
      "UGI DATASET\n",
      "\n",
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.3749657954297069\n",
      "\tR^2 score: -3.875775365020515\n",
      "Random Forest\n",
      "\tMSE: 0.09943341322158811\n",
      "\tR^2 score: -0.2929578979067451\n",
      "Gradient Boosting\n",
      "\tMSE: 0.11951465378234642\n",
      "\tR^2 score: -0.5540793634339953\n",
      "Neural Network\n",
      "\tMSE: 0.3220560709764535\n",
      "\tR^2 score: -3.1877767950081255\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.17212883130038986\n",
      "\tR^2 score: -1.2382348616689902\n",
      "Random Forest\n",
      "\tMSE: 0.1067664256629503\n",
      "\tR^2 score: -0.3883109190323357\n",
      "Gradient Boosting\n",
      "\tMSE: 0.1332500247947153\n",
      "\tR^2 score: -0.7326838773064603\n",
      "Neural Network\n",
      "\tMSE: 0.14050422043595787\n",
      "\tR^2 score: -0.8270120235846465\n"
     ]
    }
   ],
   "source": [
    "# GAP = 4 features, UGI = 3 features\n",
    "\n",
    "gap_df = gap_align_df.join(gap_meta_df['ags']).dropna(axis=1)\n",
    "gap_X = gap_df.drop(['ags'], axis=1)\n",
    "gap_y = gap_df['ags']\n",
    "\n",
    "ugi_df = ugi_align_df.join(ugi_meta_df['ags']).dropna(axis=1)\n",
    "ugi_X = ugi_df.drop(['ags'], axis=1)\n",
    "ugi_y = ugi_df['ags']\n",
    "\n",
    "dataset_params = {\n",
    "    'GAP': (gap_X, gap_y),\n",
    "    'UGI': (ugi_X, ugi_y)\n",
    "}\n",
    "\n",
    "for key, (X, y) in dataset_params.items():\n",
    "    print()\n",
    "    print(key, 'DATASET')\n",
    "    print()\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "    gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "    mlpr = MLPRegressor(hidden_layer_sizes=(2), max_iter=1000, activation='relu', random_state=0)\n",
    "    \n",
    "    print('Feature percentage = 100%\\n')\n",
    "    data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "    \n",
    "    feat_perc = 50\n",
    "    print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "    data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cde510c-9eb7-4621-944a-5c5cada8c97f",
   "metadata": {},
   "source": [
    "#### Exp 5 - Individual Align Data Groups (Excluding NaN Rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ceb1d9a-ee48-4a71-8698-64c218c8a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GAP DATASET\n",
      "\n",
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.22865801111357653\n",
      "\tR^2 score: -2.723881733059376\n",
      "Random Forest\n",
      "\tMSE: 0.06014012026721725\n",
      "\tR^2 score: 0.020569215150551212\n",
      "Gradient Boosting\n",
      "\tMSE: 0.05696748319238145\n",
      "\tR^2 score: 0.0722381909763733\n",
      "Neural Network\n",
      "\tMSE: 0.19003681675104775\n",
      "\tR^2 score: -2.0949041630405425\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.07815467216084747\n",
      "\tR^2 score: -0.2728124179671203\n",
      "Random Forest\n",
      "\tMSE: 0.07443690835698023\n",
      "\tR^2 score: -0.21226560987748888\n",
      "Gradient Boosting\n",
      "\tMSE: 0.08618064590660066\n",
      "\tR^2 score: -0.4035219298546302\n",
      "Neural Network\n",
      "\tMSE: 0.14395955093366944\n",
      "\tR^2 score: -1.3444984035789695\n",
      "\n",
      "UGI DATASET\n",
      "\n",
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.3749657954297069\n",
      "\tR^2 score: -3.875775365020515\n",
      "Random Forest\n",
      "\tMSE: 0.09943341322158811\n",
      "\tR^2 score: -0.2929578979067451\n",
      "Gradient Boosting\n",
      "\tMSE: 0.11951465378234642\n",
      "\tR^2 score: -0.5540793634339953\n",
      "Neural Network\n",
      "\tMSE: 0.39427695487133646\n",
      "\tR^2 score: -4.126883270389798\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.17212883130038986\n",
      "\tR^2 score: -1.2382348616689902\n",
      "Random Forest\n",
      "\tMSE: 0.1067664256629503\n",
      "\tR^2 score: -0.3883109190323357\n",
      "Gradient Boosting\n",
      "\tMSE: 0.1332500247947153\n",
      "\tR^2 score: -0.7326838773064603\n",
      "Neural Network\n",
      "\tMSE: 0.37064397794796844\n",
      "\tR^2 score: -3.819577675880825\n"
     ]
    }
   ],
   "source": [
    "# GAP = 9 features, UGI = 8 features\n",
    "\n",
    "gap_df = gap_align_df.join(gap_meta_df['ags']).dropna()\n",
    "gap_X = gap_df.drop(['ags'], axis=1)\n",
    "gap_y = gap_df['ags']\n",
    "\n",
    "ugi_df = ugi_align_df.join(ugi_meta_df['ags']).dropna()\n",
    "ugi_X = ugi_df.drop(['ags'], axis=1)\n",
    "ugi_y = ugi_df['ags']\n",
    "\n",
    "dataset_params = {\n",
    "    'GAP': (gap_X, gap_y), \n",
    "    'UGI': (ugi_X, ugi_y)\n",
    "}\n",
    "\n",
    "for key, (X, y) in dataset_params.items():\n",
    "    print()\n",
    "    print(key, 'DATASET')\n",
    "    print()\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "    gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "    mlpr = MLPRegressor(hidden_layer_sizes=(4), max_iter=1000, activation='relu', random_state=0)\n",
    "    \n",
    "    print('Feature percentage = 100%\\n')\n",
    "    data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "    \n",
    "    feat_perc = 50\n",
    "    print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "    data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d46e7-4c2e-4974-b689-316b23009969",
   "metadata": {},
   "source": [
    "#### Exp 6 - Combined Dom Data Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "425ea0d4-973a-49a7-82d3-b46828b643fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.0726934259476935\n",
      "\tR^2 score: -0.017064349503219\n",
      "Random Forest\n",
      "\tMSE: 0.07949499706864026\n",
      "\tR^2 score: -0.11222612537966725\n",
      "Gradient Boosting\n",
      "\tMSE: 0.11984148163934925\n",
      "\tR^2 score: -0.676719689270527\n",
      "Neural Network\n",
      "\tMSE: 0.08384967273143305\n",
      "\tR^2 score: -0.17315302918886077\n"
     ]
    }
   ],
   "source": [
    "# 1 feature\n",
    "\n",
    "df = dom_df.join(meta_df['ags'])\n",
    "X = df.drop(['ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(1), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "print('Feature percentage = 100%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "# Only one feature in this data group - no need for feature selection\n",
    "# feat_perc = 50\n",
    "# print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "# data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f08c52-b1f2-4dbd-84cb-f9cbb9ba433c",
   "metadata": {},
   "source": [
    "#### Exp 7 - Individual Dom Data Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd62f557-3c0b-4b0f-81a9-44d39c9a589b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GAP DATASET\n",
      "\n",
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.06160913134257484\n",
      "\tR^2 score: -0.11634190797993682\n",
      "Random Forest\n",
      "\tMSE: 0.07548188669294821\n",
      "\tR^2 score: -0.36771273303931573\n",
      "Gradient Boosting\n",
      "\tMSE: 0.08179184659854187\n",
      "\tR^2 score: -0.48204761371015437\n",
      "Neural Network\n",
      "\tMSE: 0.31888671244203387\n",
      "\tR^2 score: -4.778146733112367\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.0680677711860879\n",
      "\tR^2 score: -0.23337083159470784\n",
      "Random Forest\n",
      "\tMSE: 0.08423520306905906\n",
      "\tR^2 score: -0.5263206161812568\n",
      "Gradient Boosting\n",
      "\tMSE: 0.12404981997777097\n",
      "\tR^2 score: -1.2477514241927778\n",
      "Neural Network\n",
      "\tMSE: 0.09503588185273339\n",
      "\tR^2 score: -0.7220261893340678\n",
      "\n",
      "UGI DATASET\n",
      "\n",
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.07971960608133838\n",
      "\tR^2 score: -0.036614262362488326\n",
      "Random Forest\n",
      "\tMSE: 0.08025321017087461\n",
      "\tR^2 score: -0.043552851711560425\n",
      "Gradient Boosting\n",
      "\tMSE: 0.11325141747065386\n",
      "\tR^2 score: -0.47263691271964103\n",
      "Neural Network\n",
      "\tMSE: 0.09384635743589918\n",
      "\tR^2 score: -0.22030799411581592\n"
     ]
    }
   ],
   "source": [
    "# GAP = 5 features, UGI = 1 feature\n",
    "\n",
    "gap_df = gap_dom_df.join(gap_meta_df['ags'])\n",
    "gap_X = gap_df.drop(['ags'], axis=1)\n",
    "gap_y = gap_df['ags']\n",
    "\n",
    "ugi_df = ugi_dom_df.join(ugi_meta_df['ags'])\n",
    "ugi_X = ugi_df.drop(['ags'], axis=1)\n",
    "ugi_y = ugi_df['ags']\n",
    "\n",
    "dataset_params = {\n",
    "    'GAP': {\n",
    "        'data': (gap_X, gap_y),\n",
    "        'mlpr': MLPRegressor(\n",
    "            hidden_layer_sizes=(3), max_iter=1000, activation='relu', random_state=0\n",
    "        ),\n",
    "        'feat_perc': 50\n",
    "    },\n",
    "    'UGI': {\n",
    "        'data': (ugi_X, ugi_y),\n",
    "        'mlpr': MLPRegressor(\n",
    "            hidden_layer_sizes=(1), max_iter=1000, activation='relu', random_state=0\n",
    "        ),\n",
    "        'feat_perc': None\n",
    "    }\n",
    "}\n",
    "\n",
    "for key, params in dataset_params.items():\n",
    "    print()\n",
    "    print(key, 'DATASET')\n",
    "    print()\n",
    "\n",
    "    X, y = params['data']\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "    gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "    mlpr = params['mlpr']\n",
    "    \n",
    "    print('Feature percentage = 100%\\n')\n",
    "    data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "    feat_perc = params['feat_perc']\n",
    "    \n",
    "    if feat_perc:\n",
    "        print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "        data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7c1d7-1a4e-422c-9215-cd5ecbcfa328",
   "metadata": {},
   "source": [
    "#### Exp 8 - Combined Polite Data Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eb0c817-699a-429d-93f3-c28ee957a6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.05481660954954535\n",
      "\tR^2 score: 0.23305280213926627\n",
      "Random Forest\n",
      "\tMSE: 0.06620540932329208\n",
      "\tR^2 score: 0.07371043957345769\n",
      "Gradient Boosting\n",
      "\tMSE: 0.08037705351000422\n",
      "\tR^2 score: -0.12456710599882914\n",
      "Neural Network\n",
      "\tMSE: 0.11104649014670652\n",
      "\tR^2 score: -0.5536676775550875\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.061077136933215766\n",
      "\tR^2 score: 0.14546084828636252\n",
      "Random Forest\n",
      "\tMSE: 0.06587315427961414\n",
      "\tR^2 score: 0.0783590684619988\n",
      "Gradient Boosting\n",
      "\tMSE: 0.06559523659069316\n",
      "\tR^2 score: 0.08224745547654455\n",
      "Neural Network\n",
      "\tMSE: 0.08925002169516945\n",
      "\tR^2 score: -0.248710101018782\n"
     ]
    }
   ],
   "source": [
    "# 6 features\n",
    "\n",
    "df = polite_df.join(meta_df['ags'])\n",
    "X = df.drop(['ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(3), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "print('Feature percentage = 100%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "feat_perc = 50\n",
    "print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0049217d-f295-4b1f-a1a3-bb1467ed8806",
   "metadata": {},
   "source": [
    "#### Exp 9 - Combined Psych Data Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfa1cf32-0e54-49a9-8431-81781e0c77dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.07935142360289507\n",
      "\tR^2 score: -0.1102173680313876\n",
      "Random Forest\n",
      "\tMSE: 0.08034156023789146\n",
      "\tR^2 score: -0.12407051443992967\n",
      "Gradient Boosting\n",
      "\tMSE: 0.1005927527095222\n",
      "\tR^2 score: -0.40740790883710654\n",
      "Neural Network\n",
      "\tMSE: 0.2210716960893296\n",
      "\tR^2 score: -2.0930464185090654\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.07131590979355545\n",
      "\tR^2 score: 0.0022086803887370055\n",
      "Random Forest\n",
      "\tMSE: 0.0869490691179675\n",
      "\tR^2 score: -0.21651713713435106\n",
      "Gradient Boosting\n",
      "\tMSE: 0.12557182162443262\n",
      "\tR^2 score: -0.7568937137215788\n",
      "Neural Network\n",
      "\tMSE: 0.1867989260447697\n",
      "\tR^2 score: -1.6135310824713125\n"
     ]
    }
   ],
   "source": [
    "# 13 features\n",
    "\n",
    "df = psych_df.join(meta_df['ags'])\n",
    "X = df.drop(['ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(6), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "print('Feature percentage = 100%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "feat_perc = 50\n",
    "print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7ab799-83b2-417d-a704-6ab413fe20c6",
   "metadata": {},
   "source": [
    "#### Exp 10 - Combined Rhythm Data Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a3cdac0-6eba-459c-a282-e36e234a5fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.134964926817159\n",
      "\tR^2 score: -0.8883140216532712\n",
      "Random Forest\n",
      "\tMSE: 0.07120351695456473\n",
      "\tR^2 score: 0.003781185029791745\n",
      "Gradient Boosting\n",
      "\tMSE: 0.08444319878261519\n",
      "\tR^2 score: -0.181457138938663\n",
      "Neural Network\n",
      "\tMSE: 0.27695515836084367\n",
      "\tR^2 score: -2.874920108766314\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.11417296609416322\n",
      "\tR^2 score: -0.5974106595962083\n",
      "Random Forest\n",
      "\tMSE: 0.07136058105067358\n",
      "\tR^2 score: 0.0015836782998956966\n",
      "Gradient Boosting\n",
      "\tMSE: 0.07687708692362734\n",
      "\tR^2 score: -0.0755985618278916\n",
      "Neural Network\n",
      "\tMSE: 0.15666227560072885\n",
      "\tR^2 score: -1.1918848004247193\n"
     ]
    }
   ],
   "source": [
    "# 9 features\n",
    "\n",
    "df = rhythm_df.join(meta_df['ags'])\n",
    "X = df.drop(['ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(5), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "print('Feature percentage = 100%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "feat_perc = 50\n",
    "print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831d0fde-0b92-4c5c-a6b9-4066e468a5b5",
   "metadata": {},
   "source": [
    "#### Exp 11 - Individual Rhythm Data Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a13801c-29b7-4781-9713-0254a79e260e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GAP DATASET\n",
      "\n",
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.23242054603535947\n",
      "\tR^2 score: -3.2114016244139476\n",
      "Random Forest\n",
      "\tMSE: 0.05532443519011045\n",
      "\tR^2 score: -0.002464800138489931\n",
      "Gradient Boosting\n",
      "\tMSE: 0.06503517110731065\n",
      "\tR^2 score: -0.17842088368426245\n",
      "Neural Network\n",
      "\tMSE: 0.32272626149014044\n",
      "\tR^2 score: -4.847718392649527\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.1619953705823595\n",
      "\tR^2 score: -1.93531522258061\n",
      "Random Forest\n",
      "\tMSE: 0.05719670583391045\n",
      "\tR^2 score: -0.03638987158825002\n",
      "Gradient Boosting\n",
      "\tMSE: 0.0722421956528094\n",
      "\tR^2 score: -0.30901034918481685\n",
      "Neural Network\n",
      "\tMSE: 1.6050972366235725\n",
      "\tR^2 score: -28.08395675410924\n",
      "\n",
      "UGI DATASET\n",
      "\n",
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.23598552216591723\n",
      "\tR^2 score: -2.068579613133758\n",
      "Random Forest\n",
      "\tMSE: 0.08713182957174519\n",
      "\tR^2 score: -0.1329972848542742\n",
      "Gradient Boosting\n",
      "\tMSE: 0.09723392022311436\n",
      "\tR^2 score: -0.26435733244662485\n",
      "Neural Network\n",
      "\tMSE: 0.32714888178907614\n",
      "\tR^2 score: -3.253999906026662\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.16019543992379612\n",
      "\tR^2 score: -1.0830619461542161\n",
      "Random Forest\n",
      "\tMSE: 0.10445012541317417\n",
      "\tR^2 score: -0.35819147925008354\n",
      "Gradient Boosting\n",
      "\tMSE: 0.13209885862941795\n",
      "\tR^2 score: -0.7177149716136901\n",
      "Neural Network\n",
      "\tMSE: 0.20005068184800026\n",
      "\tR^2 score: -1.6013097679809318\n"
     ]
    }
   ],
   "source": [
    "# GAP = 13 features, UGI = 9 features\n",
    "\n",
    "gap_df = gap_rhythm_df.join(gap_meta_df['ags'])\n",
    "gap_X = gap_df.drop(['ags'], axis=1)\n",
    "gap_y = gap_df['ags']\n",
    "\n",
    "ugi_df = ugi_rhythm_df.join(ugi_meta_df['ags'])\n",
    "ugi_X = ugi_df.drop(['ags'], axis=1)\n",
    "ugi_y = ugi_df['ags']\n",
    "\n",
    "dataset_params = {\n",
    "    'GAP': {\n",
    "        'data': (gap_X, gap_y),\n",
    "        'mlpr': MLPRegressor(\n",
    "            hidden_layer_sizes=(6), max_iter=1000, activation='relu', random_state=0\n",
    "        )\n",
    "    },\n",
    "    'UGI': {\n",
    "        'data': (ugi_X, ugi_y),\n",
    "        'mlpr': MLPRegressor(\n",
    "            hidden_layer_sizes=(4), max_iter=1000, activation='relu', random_state=0\n",
    "        )\n",
    "    }\n",
    "}\n",
    "\n",
    "for key, params in dataset_params.items():\n",
    "    print()\n",
    "    print(key, 'DATASET')\n",
    "    print()\n",
    "\n",
    "    X, y = params['data']\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "    gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "    mlpr = params['mlpr']\n",
    "    \n",
    "    print('Feature percentage = 100%\\n')\n",
    "    data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "    feat_perc = 50\n",
    "    print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "    data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d56a16-e318-4358-b1f4-be7430b05af2",
   "metadata": {},
   "source": [
    "#### Exp 12 - Combined Meta-Polite Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ace6d32a-e9d4-4256-8891-9e7f5fbba0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.06110900613183924\n",
      "\tR^2 score: 0.14501496166945582\n",
      "Random Forest\n",
      "\tMSE: 0.06836401055455123\n",
      "\tR^2 score: 0.043509134180489295\n",
      "Gradient Boosting\n",
      "\tMSE: 0.08291306763063218\n",
      "\tR^2 score: -0.16004885030103577\n",
      "Neural Network\n",
      "\tMSE: 0.1391112818991941\n",
      "\tR^2 score: -0.9463262817626494\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.06189060976942264\n",
      "\tR^2 score: 0.13407943091320684\n",
      "Random Forest\n",
      "\tMSE: 0.06579199162889658\n",
      "\tR^2 score: 0.07949462697337517\n",
      "Gradient Boosting\n",
      "\tMSE: 0.07292864559019711\n",
      "\tR^2 score: -0.020355341908301794\n",
      "Neural Network\n",
      "\tMSE: 0.09287497502203727\n",
      "\tR^2 score: -0.29942735294776934\n"
     ]
    }
   ],
   "source": [
    "# 8 features\n",
    "\n",
    "df = meta_df.join(polite_df)\n",
    "X = df.drop(['id', 'ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(4), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "print('Feature percentage = 100%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "feat_perc = 50\n",
    "print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508286c4-2230-4ccc-a92d-8d60757e7433",
   "metadata": {},
   "source": [
    "#### Exp 13 - Combined Align-Polite Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebf9fb13-04ba-4c76-b6a3-0feb62fcc2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.07189293344388915\n",
      "\tR^2 score: 0.05884736490980946\n",
      "Random Forest\n",
      "\tMSE: 0.07135815498965425\n",
      "\tR^2 score: 0.06584816634164214\n",
      "Gradient Boosting\n",
      "\tMSE: 0.08086077121311624\n",
      "\tR^2 score: -0.058550879163187464\n",
      "Neural Network\n",
      "\tMSE: 0.29968615285098565\n",
      "\tR^2 score: -2.9232007785004477\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.06403229188080312\n",
      "\tR^2 score: 0.1617512688988143\n",
      "Random Forest\n",
      "\tMSE: 0.07019211827911173\n",
      "\tR^2 score: 0.08111278930483645\n",
      "Gradient Boosting\n",
      "\tMSE: 0.07739211529279633\n",
      "\tR^2 score: -0.013142596272933904\n",
      "Neural Network\n",
      "\tMSE: 0.26501782883770875\n",
      "\tR^2 score: -2.4693566670382037\n"
     ]
    }
   ],
   "source": [
    "# 14 features\n",
    "\n",
    "df = align_df.join(polite_df).join(meta_df['ags']).dropna()\n",
    "X = df.drop(['ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(7), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "print('Feature percentage = 100%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "feat_perc = 50\n",
    "print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2fb7c4-d28d-4e0f-b264-2acfcc5fd716",
   "metadata": {},
   "source": [
    "#### Exp 14 - Combined Dom-Polite Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a080081-3ef6-4c75-8be6-5d147b2cc504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.056616932151795626\n",
      "\tR^2 score: 0.20786422542159788\n",
      "Random Forest\n",
      "\tMSE: 0.07041593237448274\n",
      "\tR^2 score: 0.014800396026894092\n",
      "Gradient Boosting\n",
      "\tMSE: 0.08250981226257516\n",
      "\tR^2 score: -0.15440684549455264\n",
      "Neural Network\n",
      "\tMSE: 0.08977889653698627\n",
      "\tR^2 score: -0.2561096662469786\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.06198269740559769\n",
      "\tR^2 score: 0.13279101933316861\n",
      "Random Forest\n",
      "\tMSE: 0.06580581482038664\n",
      "\tR^2 score: 0.07930122468042222\n",
      "Gradient Boosting\n",
      "\tMSE: 0.06903815130467783\n",
      "\tR^2 score: 0.03407713239267318\n",
      "Neural Network\n",
      "\tMSE: 0.1549833841918077\n",
      "\tR^2 score: -1.1683951852849739\n"
     ]
    }
   ],
   "source": [
    "# 7 features\n",
    "\n",
    "df = dom_df.join(polite_df).join(meta_df['ags'])\n",
    "X = df.drop(['ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(4), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "print('Feature percentage = 100%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "feat_perc = 50\n",
    "print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e371a66a-c26e-4ccc-ab21-4633de746e62",
   "metadata": {},
   "source": [
    "#### Exp 15 - Combined Psych-Polite Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d015a190-4d3e-4bbe-9abe-2889d81a7e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.08986235563891984\n",
      "\tR^2 score: -0.25727735474303715\n",
      "Random Forest\n",
      "\tMSE: 0.07597140877683156\n",
      "\tR^2 score: -0.06292708647477041\n",
      "Gradient Boosting\n",
      "\tMSE: 0.08488349640833304\n",
      "\tR^2 score: -0.18761740738729493\n",
      "Neural Network\n",
      "\tMSE: 0.2866119739216339\n",
      "\tR^2 score: -3.010030027009468\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.06544867578407391\n",
      "\tR^2 score: 0.08429800914771324\n",
      "Random Forest\n",
      "\tMSE: 0.0776493881368468\n",
      "\tR^2 score: -0.08640394100494109\n",
      "Gradient Boosting\n",
      "\tMSE: 0.08627212633391887\n",
      "\tR^2 score: -0.20704593168030172\n",
      "Neural Network\n",
      "\tMSE: 0.18909319208440573\n",
      "\tR^2 score: -1.6456304940311521\n"
     ]
    }
   ],
   "source": [
    "# 19 features\n",
    "\n",
    "df = psych_df.join(polite_df).join(meta_df['ags'])\n",
    "X = df.drop(['ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(9), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "print('Feature percentage = 100%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "feat_perc = 50\n",
    "print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02af028-e012-4dc7-a4be-c0781631a346",
   "metadata": {},
   "source": [
    "#### Exp 16 - Combined Rhythm-Polite Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c29b28aa-277a-4434-8c4b-72d978e889d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature percentage = 100%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.11398343633873705\n",
      "\tR^2 score: -0.594758921080641\n",
      "Random Forest\n",
      "\tMSE: 0.06927899586318771\n",
      "\tR^2 score: 0.03070744096543876\n",
      "Gradient Boosting\n",
      "\tMSE: 0.06473834145764949\n",
      "\tR^2 score: 0.09423640055265958\n",
      "Neural Network\n",
      "\tMSE: 0.3747174552397324\n",
      "\tR^2 score: -4.242726696292023\n",
      "\n",
      "Feature percentage = 50%\n",
      "\n",
      "Linear Regression\n",
      "\tMSE: 0.11324124719525562\n",
      "\tR^2 score: -0.5843748442733869\n",
      "Random Forest\n",
      "\tMSE: 0.06158652202497833\n",
      "\tR^2 score: 0.13833396700038614\n",
      "Gradient Boosting\n",
      "\tMSE: 0.05258795763713256\n",
      "\tR^2 score: 0.2642341968529809\n",
      "Neural Network\n",
      "\tMSE: 0.1914629892318055\n",
      "\tR^2 score: -1.6787866723616247\n"
     ]
    }
   ],
   "source": [
    "# 15 features\n",
    "\n",
    "df = rhythm_df.join(polite_df).join(meta_df['ags'])\n",
    "X = df.drop(['ags'], axis=1)\n",
    "y = df['ags']\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfr = RandomForestRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=3, max_features=1/3, random_state=0)\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(7), max_iter=1000, activation='relu', random_state=0)\n",
    "\n",
    "print('Feature percentage = 100%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr)\n",
    "\n",
    "feat_perc = 50\n",
    "print(f'\\nFeature percentage = {feat_perc}%\\n')\n",
    "data_group_regression(X, y, lr, rfr, gbr, mlpr, feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c963c2e0-790c-4fc0-b338-393d633884b9",
   "metadata": {},
   "source": [
    "## Summary of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5ef87-de4e-4519-b15c-6b713bbcde89",
   "metadata": {},
   "source": [
    "Most experiments do not require a summary due to the negative R2 scores (revealing that the features, or at least the models manipulating the features, are useless). Here are the experiment numbers that had R2 scores above X on any model with or without feature selection (groups are mutually exclusive):\n",
    "\n",
    "X = 0.05\n",
    "- 1, 5, 15\n",
    "\n",
    "X = 0.1\n",
    "- 4, 12, 13\n",
    "\n",
    "X = 0.2\n",
    "- 8, 14, 16\n",
    "\n",
    "The most significant features are those of the polite data group, which were used in the experiments with the best results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
